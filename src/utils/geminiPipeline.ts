// Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ Python ì½”ë“œ ìƒì„±

/**
 * localStorageì—ì„œ ì‚¬ìš©ìê°€ ì…ë ¥í•œ API í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
 * ì‚¬ìš©ìëŠ” UIì—ì„œ ì§ì ‘ Gemini API í‚¤ë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.
 */
const getApiKey = (): string | null => {
    return localStorage.getItem('gemini_api_key') || null;
};

export interface NodeGuide {
    step: number;
    nodeType: string;
    nodeName: string;
    description: string;
    reason?: string; // ì´ ë…¸ë“œë¥¼ ì™œ ì‚¬ìš©í•˜ëŠ”ì§€ ì„¤ëª…
    settings?: Record<string, any>;
    connections?: {
        from?: { step: number; output: string; input: string }[];
        to?: { step: number; output: string; input: string }[];
    };
}

export interface CodeGenerationResult {
    code: string;
    nodeGuide: NodeGuide[];
}

/**
 * Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ë¡œë¶€í„° Python ì½”ë“œì™€ ë…¸ë“œ ë°°ì¹˜ ê°€ì´ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
 */
export async function generatePythonCode(userPrompt: string): Promise<CodeGenerationResult> {
    const apiKey = getApiKey();
    if (!apiKey) throw new Error('API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');

    const API_URL = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?key=${apiKey}`;
    
    const systemPrompt = `ë‹¹ì‹ ì€ ë¨¸ì‹ ëŸ¬ë‹ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” scikit-learn ê¸°ë°˜ Python ì½”ë“œë¥¼ ìƒì„±í•˜ê³ , **ì´ˆë³´ìë¥¼ ìœ„í•œ** ë…¸ë“œ ê¸°ë°˜ ì—ë””í„°ì—ì„œ êµ¬í˜„í•˜ê¸° ìœ„í•œ **ìƒì„¸í•œ ê°€ì´ë“œ**ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.

**ğŸ¯ í•µì‹¬ ì›ì¹™**:
1. nodeNameì€ ë°˜ë“œì‹œ "ì˜ì–´ì´ë¦„ (í•œêµ­ì–´ì„¤ëª…)" í˜•ì‹ìœ¼ë¡œ ì‘ì„± (ì˜ˆ: "Data Loader (ë°ì´í„° ë¡œë”)")
2. ë…¸ë“œ ì—°ê²° ì •ë³´ë¥¼ ëª…í™•íˆ í¬í•¨
3. **ì†Œì¼“ ì´ë¦„ì€ ì´ˆë³´ìê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ í•œêµ­ì–´ ì‚¬ìš©** (í›ˆë ¨ìš©, í…ŒìŠ¤íŠ¸ìš©, ëª¨ë¸, ì˜ˆì¸¡ê²°ê³¼)
4. ê° ë…¸ë“œì— ëŒ€í•´ "ì™œ ì´ ë…¸ë“œë¥¼ ì‚¬ìš©í•˜ëŠ”ì§€" reasonì„ **ì´ˆë³´ì ëˆˆë†’ì´**ë¡œ ì„¤ëª…

**ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ JSON)**:
\`\`\`json
{
  "code": "ì™„ì „í•œ Python ì½”ë“œ (X_train, y_train, X_test, y_test ë³€ìˆ˜ ì‚¬ìš©)",
  "nodeGuide": [
    {
      "step": 1,
      "nodeType": "dataLoader",
      "nodeName": "Data Loader (ë°ì´í„° ë¡œë”)",
      "description": "iris.csv íŒŒì¼ì—ì„œ ì•„ì´ë¦¬ìŠ¤ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.",
      "reason": "ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ì˜ ì²« ë‹¨ê³„ëŠ” ë¶„ì„í•  ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ CSV íŒŒì¼ì—ëŠ” ì•„ì´ë¦¬ìŠ¤ ê½ƒì˜ ê½ƒë°›ì¹¨ ê¸¸ì´/ë„ˆë¹„, ê½ƒì ê¸¸ì´/ë„ˆë¹„ì™€ í’ˆì¢… ì •ë³´ê°€ ë“¤ì–´ìˆìŠµë‹ˆë‹¤.",
      "settings": { "fileName": "iris.csv" },
      "connections": {
        "from": [],
        "to": [{ "step": 2, "output": "ë°ì´í„°", "input": "ë°ì´í„°" }]
      }
    }
  ]
}
\`\`\`

**ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ë…¸ë“œ íƒ€ì… ë° ì •í™•í•œ ì†Œì¼“ ì´ë¦„**:

âš ï¸ **ì¤‘ìš”**: ì†Œì¼“ ì´ë¦„ì€ ì•„ë˜ í‘œì‹œëœ **ì •í™•í•œ ì˜ë¬¸ ì´ë¦„**ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤!

1. **dataLoader** - "Data Loader (ë°ì´í„° ë¡œë”)"
   - ì…ë ¥: ì—†ìŒ
   - ì¶œë ¥: **data** (ì •í™•í•œ ì´ë¦„: "data")
   - settings: { fileName: "íŒŒì¼ëª….csv" }

2. **preprocess** - "Preprocess (ì „ì²˜ë¦¬)"
   - ì…ë ¥: **data** (ì •í™•í•œ ì´ë¦„: "data")
   - ì¶œë ¥: **data** (ì •í™•í•œ ì´ë¦„: "data")
   - settings: { method: "fillna" | "drop_duplicates" | "drop_columns" | "rename_columns" | "encode_categorical", params: "ì˜µì…˜ê°’" }
   - ğŸ’¡ ë°ì´í„° ì „ì²˜ë¦¬: ê²°ì¸¡ì¹˜ ì²˜ë¦¬, ì¤‘ë³µ ì œê±°, ì»¬ëŸ¼ ì‚­ì œ, ì»¬ëŸ¼ëª… ì •ë¦¬, ë²”ì£¼í˜• ì¸ì½”ë”©
   - method ì˜µì…˜:
     * fillna: ê²°ì¸¡ì¹˜ ì±„ìš°ê¸° (ìˆ˜ì¹˜í˜•=í‰ê· , ë²”ì£¼í˜•=ìµœë¹ˆê°’) - params ë¶ˆí•„ìš”
     * drop_duplicates: ì¤‘ë³µ í–‰ ì œê±° - params ë¶ˆí•„ìš”
     * drop_columns: íŠ¹ì • ì»¬ëŸ¼ ì‚­ì œ - **params í•„ìˆ˜!** ì˜ˆ: "id,timestamp,ë¶ˆí•„ìš”ì»¬ëŸ¼ëª…"
     * rename_columns: ì»¬ëŸ¼ëª… ì •ë¦¬ (ì†Œë¬¸ì, ê³µë°±â†’ì–¸ë”ìŠ¤ì½”ì–´) - params ë¶ˆí•„ìš”
     * encode_categorical: ë²”ì£¼í˜• ë°ì´í„° ì¸ì½”ë”© (LabelEncoder) - params ë¶ˆí•„ìš”
   - âš ï¸ **ì¤‘ìš”**: drop_columns ì‚¬ìš© ì‹œ ë°˜ë“œì‹œ settingsì— params í¬í•¨: { method: "drop_columns", params: "ì‚­ì œí• ì»¬ëŸ¼1,ì‚­ì œí• ì»¬ëŸ¼2" }

3. **dataSplit** - "Data Split (ë°ì´í„° ë¶„í• )"
   - ì…ë ¥: **data** (ì •í™•í•œ ì´ë¦„: "data")
   - ì¶œë ¥: **train**, **test** (ì •í™•í•œ ì´ë¦„: "train", "test")
   - settings: { ratio: 0.8, targetColumn: "ì»¬ëŸ¼ëª…" }
   - ğŸ’¡ ì¤‘ìš”: ì¶œë ¥ì€ ì •í™•íˆ "train"ê³¼ "test"ì…ë‹ˆë‹¤

4. **scaler** - "Scaler (ì •ê·œí™”)"
   - ì…ë ¥: **data** (ì •í™•í•œ ì´ë¦„: "data")
   - ì¶œë ¥: **data** (ì •í™•í•œ ì´ë¦„: "data")
   - settings: { method: "StandardScaler" ë˜ëŠ” "MinMaxScaler" }
   - ğŸ’¡ í›ˆë ¨ìš© ë°ì´í„°ë¥¼ ì •ê·œí™”í•©ë‹ˆë‹¤

5. **featureSelection** - "Feature Selection (í”¼ì²˜ ì„ íƒ)"
   - ì…ë ¥: **data** (ì •í™•í•œ ì´ë¦„: "data")
   - ì¶œë ¥: **data** (ì •í™•í•œ ì´ë¦„: "data")
   - settings: { method: "SelectKBest", k: 10 }
   - ğŸ’¡ í›ˆë ¨ìš© ë°ì´í„°ì—ì„œ ì¤‘ìš”í•œ íŠ¹ì„±ë§Œ ì„ íƒí•©ë‹ˆë‹¤

6. **classifier** - "Classifier (ë¶„ë¥˜ ëª¨ë¸)"
   - ì…ë ¥: **train** (ì •í™•í•œ ì´ë¦„: "train")
   - ì¶œë ¥: **model** (ì •í™•í•œ ì´ë¦„: "model")
   - settings: { algorithm: "RandomForest", n_estimators: 100 }
   - ğŸ’¡ í›ˆë ¨ìš© ë°ì´í„°ë¡œ ë¶„ë¥˜ ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤

7. **regressor** - "Regressor (íšŒê·€ ëª¨ë¸)"
   - ì…ë ¥: **train** (ì •í™•í•œ ì´ë¦„: "train")
   - ì¶œë ¥: **model** (ì •í™•í•œ ì´ë¦„: "model")
   - settings: { algorithm: "LinearRegression" }
   - ğŸ’¡ í›ˆë ¨ìš© ë°ì´í„°ë¡œ íšŒê·€ ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤

8. **neuralNet** - "Neural Network (ì‹ ê²½ë§)"
   - ì…ë ¥: **train** (ì •í™•í•œ ì´ë¦„: "train")
   - ì¶œë ¥: **model** (ì •í™•í•œ ì´ë¦„: "model")
   - settings: { layers: "64,32", epochs: 50 }
   - ğŸ’¡ í›ˆë ¨ìš© ë°ì´í„°ë¡œ ì‹ ê²½ë§ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤

9. **hyperparamTune** - "Hyperparameter Tuning (í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹)"
   - ì…ë ¥: **train** (ì •í™•í•œ ì´ë¦„: "train")
   - ì¶œë ¥: **model** (ì •í™•í•œ ì´ë¦„: "model")
   - settings: { method: "GridSearchCV" | "RandomizedSearchCV" | "BayesSearchCV", cv: 5, n_iter: 10 }
   - ğŸ’¡ ìµœì ì˜ ì„¤ì •ê°’ì„ ì°¾ì•„ ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤

10. **clustering** - "Clustering (í´ëŸ¬ìŠ¤í„°ë§)"
   - ì…ë ¥: **train** (ì •í™•í•œ ì´ë¦„: "train")
   - ì¶œë ¥: **model**, **labels** (ì •í™•í•œ ì´ë¦„: "model", "labels")
   - settings: { 
       algorithm: "KMeans" | "DBSCAN" | "AgglomerativeClustering" | "GaussianMixture",
       param1: 3,    // KMeans: n_clusters, DBSCAN: eps, Hierarchical: n_clusters, GMM: n_components
       param2: 300   // KMeans: max_iter, DBSCAN: min_samples, Hierarchical: linkage(0-2), GMM: covariance_type(0-3)
     }
   - ğŸ’¡ ë¹„ì§€ë„ í•™ìŠµìœ¼ë¡œ ë°ì´í„°ë¥¼ ì—¬ëŸ¬ ê·¸ë£¹ìœ¼ë¡œ ìë™ ë¶„ë¥˜í•©ë‹ˆë‹¤
   - âš ï¸ ë ˆì´ë¸”ì´ ì—†ëŠ” ë°ì´í„°ì— ì‚¬ìš© (targetColumn ë¶ˆí•„ìš”)
   - ì•Œê³ ë¦¬ì¦˜ë³„ íŒŒë¼ë¯¸í„°:
     * KMeans: param1=í´ëŸ¬ìŠ¤í„° ê°œìˆ˜, param2=ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜
     * DBSCAN: param1=eps(ì´ì›ƒ ê±°ë¦¬, 0.1~2.0), param2=min_samples(ìµœì†Œ ìƒ˜í”Œ ìˆ˜)
     * AgglomerativeClustering: param1=í´ëŸ¬ìŠ¤í„° ê°œìˆ˜, param2=linkage(0=ward, 1=complete, 2=average)
     * GaussianMixture: param1=êµ¬ì„± ìš”ì†Œ ê°œìˆ˜, param2=covariance_type(0=full, 1=tied, 2=diag, 3=spherical)

11. **predict** - "Predict (ì˜ˆì¸¡)"
   - ì…ë ¥: **model**, **test** (ì •í™•í•œ ì´ë¦„: "model", "test")
   - ì¶œë ¥: **prediction** (ì •í™•í•œ ì´ë¦„: "prediction")
   - settings: {}
   - ğŸ’¡ í•™ìŠµëœ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤

12. **evaluate** - "Evaluate (ëª¨ë¸ í‰ê°€)"
   - ì…ë ¥: **prediction**, **test** (ì •í™•í•œ ì´ë¦„: "prediction", "test")
   - ì¶œë ¥: **metrics** (ì •í™•í•œ ì´ë¦„: "metrics")
   - settings: {}
   - ğŸ’¡ ì˜ˆì¸¡ ê²°ê³¼ì˜ ì •í™•ë„ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤

**âš ï¸ ì†Œì¼“ ì—°ê²° ê·œì¹™ (ë§¤ìš° ì¤‘ìš”!)**:
- ëª¨ë“  ì†Œì¼“ ì´ë¦„ì€ **ì •í™•í•œ ì˜ë¬¸ ì´ë¦„**ì„ ì‚¬ìš©í•˜ì„¸ìš”: data, train, test, model, prediction, metrics, labels
- í•œê¸€ ì´ë¦„(ë°ì´í„°, í›ˆë ¨ìš© ë“±)ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
- ì˜ˆì‹œ: { "step": 2, "output": "data", "input": "data" } âœ…
- ì˜ëª»ëœ ì˜ˆì‹œ: { "step": 2, "output": "ë°ì´í„°", "input": "ë°ì´í„°" } âŒ

**ì™„ì „í•œ ì˜ˆì‹œ - ì•„ì´ë¦¬ìŠ¤ ë¶„ë¥˜ (ì •í™•í•œ ì†Œì¼“ ì´ë¦„ ì‚¬ìš©)**:
\`\`\`json
{
  "code": "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.metrics import accuracy_score, classification_report\\n\\n# 1. ë°ì´í„° ë¡œë”©\\ndf = pd.read_csv('iris.csv')\\n\\n# 2. ë°ì´í„° ë¶„í• \\nX = df.drop('species', axis=1)\\ny = df['species']\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# 3. ì •ê·œí™”\\nscaler = StandardScaler()\\nX_train = scaler.fit_transform(X_train)\\nX_test = scaler.transform(X_test)\\n\\n# 4. ëª¨ë¸ í›ˆë ¨\\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\\nmodel.fit(X_train, y_train)\\n\\n# 5. ì˜ˆì¸¡\\ny_pred = model.predict(X_test)\\n\\n# 6. í‰ê°€\\naccuracy = accuracy_score(y_test, y_pred)\\nprint(f'ì •í™•ë„: {accuracy:.4f}')\\nprint(classification_report(y_test, y_pred))",
  "nodeGuide": [
    {
      "step": 1,
      "nodeType": "dataLoader",
      "nodeName": "Data Loader (ì•„ì´ë¦¬ìŠ¤ ë°ì´í„° ë¡œë”)",
      "description": "iris.csv íŒŒì¼ì—ì„œ ì•„ì´ë¦¬ìŠ¤ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.",
      "reason": "ë¨¸ì‹ ëŸ¬ë‹ì˜ ì²« ë²ˆì§¸ ë‹¨ê³„ëŠ” ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ CSV íŒŒì¼ì—ëŠ” ì•„ì´ë¦¬ìŠ¤ ê½ƒì˜ ê½ƒë°›ì¹¨ ê¸¸ì´/ë„ˆë¹„, ê½ƒì ê¸¸ì´/ë„ˆë¹„ ì¸¡ì •ê°’ê³¼ í’ˆì¢… ì •ë³´ê°€ ë“¤ì–´ìˆìŠµë‹ˆë‹¤.",
      "settings": {
        "fileName": "iris.csv"
      },
      "connections": {
        "from": [],
        "to": [
          { "step": 2, "output": "data", "input": "data" }
        ]
      }
    },
    {
      "step": 2,
      "nodeType": "dataSplit",
      "nodeName": "Data Split (ë°ì´í„° ë¶„í• )",
      "description": "ë°ì´í„°ë¥¼ í›ˆë ¨ìš©(80%)ê³¼ í…ŒìŠ¤íŠ¸ìš©(20%)ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.",
      "reason": "ëª¨ë¸ì´ ì‹¤ì œë¡œ ì–¼ë§ˆë‚˜ ì˜ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ë ¤ë©´, ì¼ë¶€ ë°ì´í„°ëŠ” í•™ìŠµì— ì‚¬ìš©í•˜ê³ (í›ˆë ¨ìš©), ë‚˜ë¨¸ì§€ëŠ” ê²€ì¦ìš©(í…ŒìŠ¤íŠ¸ìš©)ìœ¼ë¡œ ë‚¨ê²¨ë‘¬ì•¼ í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ëª¨ë¸ì´ ìƒˆë¡œìš´ ë°ì´í„°ì—ì„œë„ ì˜ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
      "settings": {
        "ratio": 0.8,
        "targetColumn": "species"
      },
      "connections": {
        "from": [
          { "step": 1, "output": "data", "input": "data" }
        ],
        "to": [
          { "step": 3, "output": "train", "input": "data" },
          { "step": 5, "output": "test", "input": "test" }
        ]
      }
    },
    {
      "step": 3,
      "nodeType": "scaler",
      "nodeName": "Scaler (í‘œì¤€ ì •ê·œí™”)",
      "description": "StandardScalerë¡œ ë°ì´í„°ë¥¼ ì •ê·œí™”í•©ë‹ˆë‹¤.",
      "reason": "ê½ƒë°›ì¹¨ ê¸¸ì´(5-8cm)ì™€ ê½ƒì ë„ˆë¹„(0.1-2.5cm)ì²˜ëŸ¼ ê°’ì˜ ë²”ìœ„ê°€ ë‹¤ë¥´ë©´, í° ìˆ«ìê°€ ë” ì¤‘ìš”í•´ ë³´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì •ê·œí™”ëŠ” ëª¨ë“  ê°’ì„ ê°™ì€ ê¸°ì¤€ìœ¼ë¡œ ë§ì¶°ì„œ ê³µì •í•˜ê²Œ ë¹„êµí•  ìˆ˜ ìˆê²Œ ë§Œë“­ë‹ˆë‹¤.",
      "settings": {
        "method": "StandardScaler"
      },
      "connections": {
        "from": [
          { "step": 2, "output": "train", "input": "data" }
        ],
        "to": [
          { "step": 4, "output": "data", "input": "train" }
        ]
      }
    },
    {
      "step": 4,
      "nodeType": "classifier",
      "nodeName": "Classifier (ëœë¤ í¬ë ˆìŠ¤íŠ¸ ë¶„ë¥˜ê¸°)",
      "description": "100ê°œì˜ ê²°ì • íŠ¸ë¦¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ëœë¤ í¬ë ˆìŠ¤íŠ¸ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.",
      "reason": "ëœë¤ í¬ë ˆìŠ¤íŠ¸ëŠ” 100ê°œì˜ 'ì§ˆë¬¸ íŠ¸ë¦¬'ë¥¼ ë§Œë“¤ì–´ì„œ íˆ¬í‘œë¡œ ê²°ì •í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. í•œ ê°œì˜ íŠ¸ë¦¬ë³´ë‹¤ 100ê°œê°€ íˆ¬í‘œí•˜ë©´ ë” ì •í™•í•œ ë‹µì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§ˆì¹˜ í•œ ì‚¬ëŒ ì˜ê²¬ë³´ë‹¤ 100ëª… ì˜ê²¬ì´ ë” ë¯¿ì„ ë§Œí•œ ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤.",
      "settings": {
        "algorithm": "RandomForest",
        "n_estimators": 100
      },
      "connections": {
        "from": [
          { "step": 3, "output": "data", "input": "train" }
        ],
        "to": [
          { "step": 5, "output": "model", "input": "model" }
        ]
      }
    },
    {
      "step": 5,
      "nodeType": "predict",
      "nodeName": "Predict (ì˜ˆì¸¡ ìˆ˜í–‰)",
      "description": "í•™ìŠµëœ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.",
      "reason": "ëª¨ë¸ì´ ìƒˆë¡œìš´ ê½ƒì„ ë³´ê³  ì •ë§ í’ˆì¢…ì„ ë§ì¶œ ìˆ˜ ìˆëŠ”ì§€ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤. í•™ìŠµí•  ë•Œ ë³´ì§€ ëª»í–ˆë˜ ë°ì´í„°ë¡œ ì‹œí—˜ì„ ë³´ëŠ” ê²ƒì…ë‹ˆë‹¤.",
      "settings": {},
      "connections": {
        "from": [
          { "step": 4, "output": "model", "input": "model" },
          { "step": 2, "output": "test", "input": "test" }
        ],
        "to": [
          { "step": 6, "output": "prediction", "input": "prediction" }
        ]
      }
    },
    {
      "step": 6,
      "nodeType": "evaluate",
      "nodeName": "Evaluate (ëª¨ë¸ í‰ê°€)",
      "description": "ì˜ˆì¸¡ ê²°ê³¼ì˜ ì •í™•ë„ë¥¼ ì¸¡ì •í•˜ê³  ìƒì„¸ ë¦¬í¬íŠ¸ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.",
      "reason": "ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ì˜ ë§ì·„ëŠ”ì§€ ì ìˆ˜ë¥¼ ë§¤ê¹ë‹ˆë‹¤. ì •í™•ë„ê°€ 95%ë¼ë©´ 100ê°œ ì¤‘ 95ê°œë¥¼ ë§ì·„ë‹¤ëŠ” ëœ»ì…ë‹ˆë‹¤. ë˜í•œ ì–´ë–¤ í’ˆì¢…ì„ ì˜ ë§ì¶”ê³  ëª» ë§ì¶”ëŠ”ì§€ë„ ì•Œë ¤ì¤ë‹ˆë‹¤.",
      "settings": {},
      "connections": {
        "from": [
          { "step": 5, "output": "prediction", "input": "prediction" },
          { "step": 2, "output": "test", "input": "test" }
        ],
        "to": []
      }
    }
  ]
}
\`\`\`

**ğŸ”‘ í•µì‹¬ ì—°ê²° ê·œì¹™ (ì •í™•í•œ ì†Œì¼“ ì´ë¦„ ì‚¬ìš©!)**:
- dataLoaderì˜ **data** â†’ dataSplitì˜ **data**
- dataSplitì˜ **train** â†’ Scaler/FeatureSelection â†’ Classifier/Regressor/NeuralNet
- dataSplitì˜ **test** â†’ Predictì˜ **test** / Evaluateì˜ **test**
- ëª¨ë¸ ë…¸ë“œ(Classifier/Regressor)ì˜ **model** â†’ Predictì˜ **model**
- Predictì˜ **prediction** â†’ Evaluateì˜ **prediction**

**ì—°ê²° ì •ë³´ ì‘ì„± ë°©ë²• (ì •í™•í•œ ì†Œì¼“ ì´ë¦„ í•„ìˆ˜!)**:
- **from**: ì´ ë…¸ë“œì˜ ì…ë ¥ ì†Œì¼“ì— ì—°ê²°ë  ì´ì „ ë…¸ë“œë“¤
  - step: ì´ì „ ë…¸ë“œì˜ ë‹¨ê³„ ë²ˆí˜¸
  - output: ì´ì „ ë…¸ë“œì˜ ì¶œë ¥ ì†Œì¼“ ì´ë¦„ (ì˜ë¬¸: data, train, test, model, prediction)
  - input: í˜„ì¬ ë…¸ë“œì˜ ì…ë ¥ ì†Œì¼“ ì´ë¦„ (ì˜ë¬¸: data, train, test, model, prediction)
- **to**: ì´ ë…¸ë“œì˜ ì¶œë ¥ ì†Œì¼“ì´ ì—°ê²°ë  ë‹¤ìŒ ë…¸ë“œë“¤
  - step: ë‹¤ìŒ ë…¸ë“œì˜ ë‹¨ê³„ ë²ˆí˜¸
  - output: í˜„ì¬ ë…¸ë“œì˜ ì¶œë ¥ ì†Œì¼“ ì´ë¦„ (ì˜ë¬¸: data, train, test, model, prediction)
  - input: ë‹¤ìŒ ë…¸ë“œì˜ ì…ë ¥ ì†Œì¼“ ì´ë¦„ (ì˜ë¬¸: data, train, test, model, prediction)

**ğŸ’¡ ê°€ì´ë“œ ì‘ì„± íŒ**:
- **reason í•„ë“œëŠ” í•„ìˆ˜**: ê° ë…¸ë“œê°€ ì™œ í•„ìš”í•œì§€ ì´ˆë³´ì ëˆˆë†’ì´ë¡œ ì„¤ëª… (ì „ë¬¸ ìš©ì–´ ìµœì†Œí™”)
- **âš ï¸ ì†Œì¼“ ì´ë¦„ì€ ë°˜ë“œì‹œ ì˜ë¬¸ ì‚¬ìš©**: data, train, test, model, prediction, metrics
- **ì—°ê²°ì€ ëª…í™•í•˜ê²Œ**: from/to ëª¨ë‘ ì‘ì„±í•˜ì—¬ ì‚¬ìš©ìê°€ ì–´ë–»ê²Œ ì—°ê²°í•´ì•¼ í•˜ëŠ”ì§€ ì •í™•íˆ ì•Œ ìˆ˜ ìˆë„ë¡

ì´ì œ ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” Python ì½”ë“œì™€ **ì´ˆë³´ìë¥¼ ìœ„í•œ ìƒì„¸í•œ** ë…¸ë“œ ê°€ì´ë“œë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­: ${userPrompt}`;

    try {
        const response = await fetch(API_URL, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                contents: [{ parts: [{ text: systemPrompt }] }],
                generationConfig: {
                    temperature: 0.7,
                    maxOutputTokens: 3072,
                }
            })
        });

        if (!response.ok) {
            const errorData = await response.json();
            throw new Error(`API ì˜¤ë¥˜: ${errorData.error?.message || response.statusText}`);
        }

        const data = await response.json();
        const text = data.candidates?.[0]?.content?.parts?.[0]?.text || '';
        
        // JSON ë¸”ë¡ ì¶”ì¶œ
        let jsonText = text.trim();
        if (jsonText.startsWith('```json')) {
            jsonText = jsonText.replace(/^```json\n/, '').replace(/\n```$/, '');
        } else if (jsonText.startsWith('```')) {
            jsonText = jsonText.replace(/^```\n/, '').replace(/\n```$/, '');
        }
        
        const result = JSON.parse(jsonText) as CodeGenerationResult;
        
        // ê¸°ë³¸ ê²€ì¦
        if (!result.code || !result.nodeGuide) {
            throw new Error('ì˜ëª»ëœ ì‘ë‹µ í˜•ì‹ì…ë‹ˆë‹¤.');
        }
        
        return result;
    } catch (error) {
        console.error('Gemini API ì˜¤ë¥˜:', error);
        throw new Error(`ì½”ë“œ ìƒì„± ì‹¤íŒ¨: ${error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}`);
    }
}

// API í‚¤ ê´€ë¦¬ í•¨ìˆ˜ëŠ” ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•ŠìŒ (í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)

/**
 * ë…¸ë“œ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±ëœ ê¸°ë³¸ ì½”ë“œë¥¼ AIë¡œ í›„ì²˜ë¦¬í•˜ì—¬ ì™„ì „í•œ í˜•íƒœë¡œ ê°œì„ í•©ë‹ˆë‹¤.
 * @param generatedCode ë…¸ë“œë¡œë¶€í„° ìƒì„±ëœ ê¸°ë³¸ Python ì½”ë“œ
 * @param userIntent ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì½”ë“œì˜ ëª©ì /ì˜ë„
 * @returns AIê°€ ê°œì„ í•œ ì™„ì „í•œ Python ì½”ë“œ
 */
export async function enhanceCodeWithAI(generatedCode: string, userIntent: string): Promise<string> {
    const apiKey = getApiKey();
    if (!apiKey) throw new Error('API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');

    const API_URL = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?key=${apiKey}`;
    
    const systemPrompt = `ë‹¹ì‹ ì€ Python ë¨¸ì‹ ëŸ¬ë‹ ì½”ë“œ ë¦¬íŒ©í† ë§ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 

**ì¤‘ìš”: ì›ë³¸ ì½”ë“œì˜ êµ¬ì¡°ì™€ ë°ì´í„°ë¥¼ ì •í™•íˆ ìœ ì§€í•˜ë©´ì„œ ê°œì„ ë§Œ í•˜ì„¸ìš”!**

ì•„ë˜ ìë™ ìƒì„±ëœ ì½”ë“œë¥¼ ë¶„ì„í•˜ê³ , **ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­**ì— ë§ì¶° ê°œì„ í•´ì£¼ì„¸ìš”.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‹ ì›ë³¸ ì½”ë“œ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
\`\`\`python
${generatedCode}
\`\`\`

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¯ ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
${userIntent}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… ê°œì„  ê°€ì´ë“œë¼ì¸
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**1. ì›ë³¸ ì½”ë“œ ë¶„ì„ (ë°˜ë“œì‹œ í™•ì¸)**
   â€¢ CSV íŒŒì¼ëª… ì¶”ì¶œ â†’ ê·¸ëŒ€ë¡œ ì‚¬ìš©
   â€¢ ì»¬ëŸ¼ëª… ì¶”ì¶œ (íŠ¹íˆ target ì»¬ëŸ¼) â†’ ì •í™•íˆ ìœ ì§€
   â€¢ train_test_split ë¹„ìœ¨ â†’ ë³€ê²½í•˜ì§€ ë§ ê²ƒ
   â€¢ ì‚¬ìš©ëœ ëª¨ë¸ â†’ ë™ì¼í•œ ì•Œê³ ë¦¬ì¦˜ ìœ ì§€
   â€¢ ì„ë² ë“œëœ CSV ë°ì´í„° â†’ ì ˆëŒ€ ì‚­ì œ ê¸ˆì§€

**2. ë³€ìˆ˜ëª… ê°œì„ **
   â€¢ step_xxxxx_model â†’ model ë˜ëŠ” regressor/classifier
   â€¢ step_xxxxx_X_train â†’ X_train
   â€¢ step_xxxxx_prediction â†’ y_pred
   â€¢ ì˜ë¯¸ ìˆê³  ê°„ê²°í•œ ì´ë¦„ìœ¼ë¡œ ë³€ê²½

**3. ì½”ë“œ êµ¬ì¡° ê°œì„ **
   â€¢ ë¶ˆí•„ìš”í•œ import ì œê±°
   â€¢ ì¤‘ë³µ ì½”ë“œ ì œê±°
   â€¢ ëª…í™•í•œ ì„¹ì…˜ êµ¬ë¶„ (ì£¼ì„ìœ¼ë¡œ)

**4. ì—ëŸ¬ ì²˜ë¦¬ (ìµœì†Œí•œ)**
   â€¢ try-exceptëŠ” í•„ìˆ˜ì ì¸ ë¶€ë¶„ë§Œ
   â€¢ ê³¼ë„í•œ í•¨ìˆ˜ ë¶„ë¦¬ ê¸ˆì§€
   â€¢ ë‹¨ìˆœí•˜ê³  ì½ê¸° ì‰½ê²Œ

**5. ì‹œê°í™” ì¶”ê°€ (ì‚¬ìš©ì ìš”êµ¬ ì‹œ)**
   â€¢ matplotlibìœ¼ë¡œ ê²°ê³¼ í”Œë¡¯
   â€¢ íŒŒì¼ëª…ì€ ì‚¬ìš©ìê°€ ìš”êµ¬í•œ ëŒ€ë¡œ
   â€¢ ê°„ë‹¨í•˜ê³  ëª…í™•í•œ ì°¨íŠ¸

**6. ê¸ˆì§€ ì‚¬í•­ ì²´í¬**
   â€¢ ì‚¬ìš©ìê°€ ê¸ˆì§€í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€
   â€¢ ì˜ˆ: "sklearn.linear_model.LinearRegression ì‚¬ìš© ê¸ˆì§€" â†’ numpy.linalg.pinv ì‚¬ìš©
   â€¢ ì›ë³¸ì— ì—†ë˜ ë³µì¡í•œ ê¸°ëŠ¥ ì¶”ê°€ ê¸ˆì§€

**7. ì¶œë ¥ íŒŒì¼ëª…**
   â€¢ ì‚¬ìš©ìê°€ ëª…ì‹œí•œ íŒŒì¼ëª… ì‚¬ìš©
   â€¢ ì˜ˆ: class_score_predict.png, model.pkl ë“±

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“¤ ì¶œë ¥ ê·œì¹™
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. **Python ì½”ë“œë§Œ** ì¶œë ¥ (ì„¤ëª… ê¸ˆì§€)
2. ì£¼ì„ì€ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ
3. ì‹¤í–‰ ê°€ëŠ¥í•œ ì™„ì „í•œ ì½”ë“œ
4. ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì‚¬ìš©: \`\`\`python ... \`\`\`
5. ì›ë³¸ì˜ ë°ì´í„° ì†ŒìŠ¤(CSV ì„ë² ë”© ë˜ëŠ” íŒŒì¼ ê²½ë¡œ) ìœ ì§€

**ì¶œë ¥ ì‹œì‘**:`;

    try {
        const response = await fetch(API_URL, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                contents: [{ parts: [{ text: systemPrompt }] }],
                generationConfig: {
                    temperature: 0.3, // ë” ì •í™•í•œ ê°œì„ ì„ ìœ„í•´ ë‚®ì¶¤
                    maxOutputTokens: 8192, // ë” ê¸´ ì½”ë“œ í—ˆìš©
                }
            })
        });

        if (!response.ok) {
            const errorData = await response.json();
            throw new Error(`API ì˜¤ë¥˜: ${errorData.error?.message || response.statusText}`);
        }

        const data = await response.json();
        let text = data.candidates?.[0]?.content?.parts?.[0]?.text || '';
        
        // ì½”ë“œ ë¸”ë¡ ì¶”ì¶œ
        text = text.trim();
        if (text.startsWith('```python')) {
            text = text.replace(/^```python\n/, '').replace(/\n```$/, '');
        } else if (text.startsWith('```')) {
            text = text.replace(/^```\n/, '').replace(/\n```$/, '');
        }
        
        return text;
    } catch (error) {
        console.error('AI ì½”ë“œ ê°œì„  ì˜¤ë¥˜:', error);
        throw new Error(`ì½”ë“œ ê°œì„  ì‹¤íŒ¨: ${error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}`);
    }
}
