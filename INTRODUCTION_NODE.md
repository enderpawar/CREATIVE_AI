# ğŸ¯ ML Pipeline Builder - ë…¸ë“œë³„ ìƒì„¸ ì—­í•  ì„¤ëª…

í˜„ì¬ êµ¬í˜„ëœ 10ê°œì˜ ML ë…¸ë“œë“¤ì˜ ì—­í• ì„ ìì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.

---

## ğŸ“Š 1. Data Source (ë°ì´í„° ì†ŒìŠ¤)

### ğŸ”¹ Data Loader (ë°ì´í„° ë¡œë”)
**ì—­í• **: ì™¸ë¶€ íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì‹œì‘ì 

**ì…ë ¥**: ì—†ìŒ (ë£¨íŠ¸ ë…¸ë“œ)  
**ì¶œë ¥**: 
- `data` - ë¡œë“œëœ DataFrame

**ì„¤ì •**:
- `fileType`: íŒŒì¼ í˜•ì‹ (CSV, JSON, SQL ë“±)
- `path`: íŒŒì¼ ê²½ë¡œ

**ìƒì„±ë˜ëŠ” ì½”ë“œ**:
```python
step_node_1 = pd.read_csv('iris.csv')
print(f"Data loaded: {step_node_1.shape}")
```

**ì‹¤ì œ í™œìš©**:
- CSV íŒŒì¼ì—ì„œ ë°ì´í„° ì½ê¸°
- ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¿¼ë¦¬ ì‹¤í–‰
- APIì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°

---

## ğŸ”§ 2. Preprocessing (ì „ì²˜ë¦¬)

### ğŸ”¹ Data Split (ë°ì´í„° ë¶„í• )
**ì—­í• **: ë°ì´í„°ë¥¼ í›ˆë ¨ìš©ê³¼ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë¶„ë¦¬

**ì…ë ¥**: 
- `data` - ì›ë³¸ ë°ì´í„°

**ì¶œë ¥**:
- `train` - í›ˆë ¨ìš© ë°ì´í„° (80%)
- `test` - í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° (20%)

**ì„¤ì •**:
- `ratio`: í›ˆë ¨ ë°ì´í„° ë¹„ìœ¨ (0.0 ~ 1.0)

**ìƒì„±ë˜ëŠ” ì½”ë“œ**:
```python
X = step_node_1.drop('target', axis=1)
y = step_node_1['target']
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
print(f"Train size: {len(X_train)}, Test size: {len(X_test)}")
```

**ì™œ í•„ìš”í•œê°€?**:
- **ê³¼ì í•© ë°©ì§€**: ëª¨ë¸ì´ í›ˆë ¨ ë°ì´í„°ë§Œ ì™¸ìš°ëŠ” ê²ƒ ë°©ì§€
- **ì¼ë°˜í™” ì„±ëŠ¥ ì¸¡ì •**: ë³¸ ì  ì—†ëŠ” ë°ì´í„°ë¡œ ì„±ëŠ¥ í‰ê°€
- **í‘œì¤€ ê´€í–‰**: MLì—ì„œ í•„ìˆ˜ì ì¸ ë‹¨ê³„

---

### ğŸ”¹ Scaler (ìŠ¤ì¼€ì¼ëŸ¬/ì •ê·œí™”)
**ì—­í• **: íŠ¹ì„±(feature)ë“¤ì˜ ë²”ìœ„ë¥¼ ë™ì¼í•˜ê²Œ ë§ì¶¤

**ì…ë ¥**: 
- `data` - ì›ë³¸ ë°ì´í„°

**ì¶œë ¥**:
- `scaled` - ì •ê·œí™”ëœ ë°ì´í„°

**ì„¤ì •**:
- `method`: ì •ê·œí™” ë°©ë²•
  - `StandardScaler`: í‰ê·  0, í‘œì¤€í¸ì°¨ 1ë¡œ ë³€í™˜
  - `MinMaxScaler`: 0~1 ë²”ìœ„ë¡œ ë³€í™˜

**ìƒì„±ë˜ëŠ” ì½”ë“œ**:
```python
step_node_3 = StandardScaler()
X_train_scaled = step_node_3.fit_transform(X_train)
X_test_scaled = step_node_3.transform(X_test)
print("Features scaled using StandardScaler")
```

**ì˜ˆì‹œ**:
```
ì›ë³¸ ë°ì´í„°:
ë‚˜ì´: [20, 30, 40, 50, 60]
ì—°ë´‰: [3000ë§Œ, 4000ë§Œ, 5000ë§Œ, 6000ë§Œ, 7000ë§Œ]

StandardScaler ì ìš© í›„:
ë‚˜ì´: [-1.41, -0.71, 0.00, 0.71, 1.41]
ì—°ë´‰: [-1.41, -0.71, 0.00, 0.71, 1.41]
```

**ì™œ í•„ìš”í•œê°€?**:
- íŠ¹ì„± ê°„ ìŠ¤ì¼€ì¼ ì°¨ì´ë¡œ ì¸í•œ í¸í–¥ ì œê±°
- ê²½ì‚¬ í•˜ê°•ë²• ì•Œê³ ë¦¬ì¦˜ì˜ ìˆ˜ë ´ ì†ë„ í–¥ìƒ
- ê±°ë¦¬ ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜(KNN, SVM)ì˜ ì„±ëŠ¥ í–¥ìƒ

---

### ğŸ”¹ Feature Selection (íŠ¹ì„± ì„ íƒ)
**ì—­í• **: ì¤‘ìš”í•œ íŠ¹ì„±ë§Œ ì„ íƒí•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒ

**ì…ë ¥**: 
- `data` - ìŠ¤ì¼€ì¼ëœ ë°ì´í„°

**ì¶œë ¥**:
- `selected` - ì„ íƒëœ íŠ¹ì„±ë“¤

**ì„¤ì •**:
- `method`: ì„ íƒ ë°©ë²• (SelectKBest, RFE ë“±)
- `k`: ì„ íƒí•  íŠ¹ì„± ê°œìˆ˜

**ìƒì„±ë˜ëŠ” ì½”ë“œ**:
```python
step_node_4 = SelectKBest(k=10)
X_train_selected = step_node_4.fit_transform(X_train_scaled, y_train)
X_test_selected = step_node_4.transform(X_test_scaled)
print(f"Selected 10 best features")
```

**íš¨ê³¼**:
- **ì°¨ì›ì˜ ì €ì£¼ ë°©ì§€**: ë¶ˆí•„ìš”í•œ íŠ¹ì„± ì œê±°
- **ê³¼ì í•© ê°ì†Œ**: ë…¸ì´ì¦ˆ ì œê±°
- **í•™ìŠµ ì†ë„ í–¥ìƒ**: ë°ì´í„° í¬ê¸° ê°ì†Œ
- **í•´ì„ ê°€ëŠ¥ì„± í–¥ìƒ**: ì¤‘ìš” ë³€ìˆ˜ë§Œ ì‚¬ìš©

---

## ğŸ¤– 3. Models (ëª¨ë¸)

### ğŸ”¹ Classifier (ë¶„ë¥˜ê¸°)
**ì—­í• **: ì¹´í…Œê³ ë¦¬ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ í•™ìŠµ

**ì…ë ¥**: 
- `train` - í›ˆë ¨ìš© ë°ì´í„°

**ì¶œë ¥**:
- `model` - í•™ìŠµëœ ë¶„ë¥˜ ëª¨ë¸

**ì„¤ì •**:
- `algorithm`: ì•Œê³ ë¦¬ì¦˜ ì„ íƒ
  - **RandomForest**: ì—¬ëŸ¬ ê²°ì • íŠ¸ë¦¬ì˜ ì•™ìƒë¸” (ì •í™•ë„ ë†’ìŒ)
  - **LogisticRegression**: ì„ í˜• ëª¨ë¸ (ë¹ ë¥´ê³  í•´ì„ ì‰¬ì›€)
  - **SVM**: ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹  (ë³µì¡í•œ ê²½ê³„ í•™ìŠµ)
- `n_estimators`: íŠ¸ë¦¬ ê°œìˆ˜ (RandomForestìš©)

**ìƒì„±ë˜ëŠ” ì½”ë“œ**:
```python
step_node_5 = RandomForestClassifier(n_estimators=100, random_state=42)
step_node_5.fit(X_train_scaled, y_train)
print("Model trained: RandomForest")
```

**í™œìš© ì˜ˆì‹œ**:
- ìŠ¤íŒ¸ ë©”ì¼ ë¶„ë¥˜ (ìŠ¤íŒ¸ / ì •ìƒ)
- ê½ƒ ì¢…ë¥˜ ë¶„ë¥˜ (Iris ë°ì´í„°ì…‹)
- ê³ ê° ì´íƒˆ ì˜ˆì¸¡ (ì´íƒˆ / ìœ ì§€)
- ì§ˆë³‘ ì§„ë‹¨ (ì–‘ì„± / ìŒì„±)

---

### ğŸ”¹ Regressor (íšŒê·€)
**ì—­í• **: ì—°ì†ì ì¸ ìˆ«ì ê°’ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ í•™ìŠµ

**ì…ë ¥**: 
- `train` - í›ˆë ¨ìš© ë°ì´í„°

**ì¶œë ¥**:
- `model` - í•™ìŠµëœ íšŒê·€ ëª¨ë¸

**ì„¤ì •**:
- `algorithm`: ì•Œê³ ë¦¬ì¦˜ ì„ íƒ
  - **LinearRegression**: ì„ í˜• íšŒê·€
  - **Ridge**: ê·œì œê°€ ìˆëŠ” ì„ í˜• íšŒê·€
  - **RandomForest**: ëœë¤ í¬ë ˆìŠ¤íŠ¸ íšŒê·€

**ìƒì„±ë˜ëŠ” ì½”ë“œ**:
```python
step_node_5 = LinearRegression()
step_node_5.fit(X_train_scaled, y_train)
print("Model trained: LinearRegression")
```

**í™œìš© ì˜ˆì‹œ**:
- ì§‘ê°’ ì˜ˆì¸¡ (í‰ìˆ˜, ìœ„ì¹˜ â†’ ê°€ê²©)
- ë§¤ì¶œ ì˜ˆì¸¡ (ë§ˆì¼€íŒ… ë¹„ìš© â†’ ë§¤ì¶œì•¡)
- ì˜¨ë„ ì˜ˆì¸¡ (ì‹œê°„, ê³„ì ˆ â†’ ì˜¨ë„)
- ì£¼ì‹ ê°€ê²© ì˜ˆì¸¡

**Classifier vs Regressor**:
```
Classifier: "ì´ ë©”ì¼ì€ ìŠ¤íŒ¸ì…ë‹ˆë‹¤" (ì¹´í…Œê³ ë¦¬)
Regressor: "ì´ ì§‘ì˜ ê°€ê²©ì€ 5ì–µì…ë‹ˆë‹¤" (ìˆ«ì)
```

---

### ğŸ”¹ Neural Network (ì‹ ê²½ë§)
**ì—­í• **: ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡ ì„ ì‚¬ìš©í•œ ë³µì¡í•œ íŒ¨í„´ í•™ìŠµ

**ì…ë ¥**: 
- `train` - í›ˆë ¨ìš© ë°ì´í„°

**ì¶œë ¥**:
- `model` - í•™ìŠµëœ ì‹ ê²½ë§ ëª¨ë¸

**ì„¤ì •**:
- `layers`: ì€ë‹‰ì¸µ êµ¬ì¡° (ì˜ˆ: "64,32" = 64ê°œ ë‰´ëŸ°, 32ê°œ ë‰´ëŸ°)
- `epochs`: í•™ìŠµ ë°˜ë³µ íšŸìˆ˜

**ìƒì„±ë˜ëŠ” ì½”ë“œ**:
```python
step_node_5 = MLPClassifier(
    hidden_layer_sizes=(64,32), 
    max_iter=50, 
    random_state=42
)
step_node_5.fit(X_train_scaled, y_train)
print("Neural Network trained with layers: [64,32]")
```

**êµ¬ì¡° ì‹œê°í™”**:
```
ì…ë ¥ì¸µ â†’ ì€ë‹‰ì¸µ1(64) â†’ ì€ë‹‰ì¸µ2(32) â†’ ì¶œë ¥ì¸µ
  [4]  â†’    [64]    â†’    [32]    â†’  [3]
```

**ì–¸ì œ ì‚¬ìš©?**:
- ë³µì¡í•œ ë¹„ì„ í˜• ê´€ê³„ê°€ ìˆì„ ë•Œ
- ë°ì´í„°ê°€ ì¶©ë¶„íˆ ë§ì„ ë•Œ (ìµœì†Œ ìˆ˜ì²œ ê°œ)
- ì´ë¯¸ì§€, ìŒì„± ë“± ê³ ì°¨ì› ë°ì´í„°

---

## ğŸ“ˆ 4. Evaluation (í‰ê°€)

### ğŸ”¹ Evaluate Model (ëª¨ë¸ í‰ê°€)
**ì—­í• **: í•™ìŠµëœ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì¸¡ì •

**ì…ë ¥**: 
- `model` - í•™ìŠµëœ ëª¨ë¸
- `test` - í…ŒìŠ¤íŠ¸ ë°ì´í„°

**ì¶œë ¥**:
- `metrics` - í‰ê°€ ì§€í‘œë“¤

**ìƒì„±ë˜ëŠ” ì½”ë“œ**:
```python
y_pred = step_node_5.predict(X_test_scaled)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.4f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred))
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
Accuracy: 0.9667
That's 96.67%!

Classification Report:
              precision    recall  f1-score
setosa            1.00      1.00      1.00
versicolor        0.93      0.93      0.93
virginica         0.93      0.93      0.93

Confusion Matrix:
[[10  0  0]
 [ 0 13  1]
 [ 0  1  5]]
```

**ì£¼ìš” ì§€í‘œ**:
- **Accuracy**: ì „ì²´ ì •í™•ë„
- **Precision**: ì˜ˆì¸¡ì´ ë§ì„ í™•ë¥ 
- **Recall**: ì‹¤ì œë¥¼ ì°¾ì•„ë‚¸ ë¹„ìœ¨
- **F1-Score**: Precisionê³¼ Recallì˜ ì¡°í™”í‰ê· 
- **Confusion Matrix**: ì˜ˆì¸¡ vs ì‹¤ì œ ë¹„êµí‘œ

---

### ğŸ”¹ Predict (ì˜ˆì¸¡)
**ì—­í• **: ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ìˆ˜í–‰

**ì…ë ¥**: 
- `model` - í•™ìŠµëœ ëª¨ë¸
- `data` - ì˜ˆì¸¡í•  ë°ì´í„°

**ì¶œë ¥**:
- `prediction` - ì˜ˆì¸¡ ê²°ê³¼

**ìƒì„±ë˜ëŠ” ì½”ë“œ**:
```python
step_node_7 = step_node_5.predict(X_test_scaled)
print(f"Predictions: {step_node_7[:10]}")  # Show first 10
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
Predictions: [0 1 2 1 0 2 1 1 1 2]
# 0=setosa, 1=versicolor, 2=virginica
```

**ì‹¤ë¬´ í™œìš©**:
- ì‹¤ì‹œê°„ ì˜ˆì¸¡ API
- ë°°ì¹˜ ì˜ˆì¸¡ (ëŒ€ëŸ‰ ë°ì´í„°)
- A/B í…ŒìŠ¤íŠ¸

---

## âš™ï¸ 5. Optimization (ìµœì í™”)

### ğŸ”¹ Hyperparameter Tuning (í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹)
**ì—­í• **: ëª¨ë¸ì˜ ìµœì  ì„¤ì •ê°’ ìë™ íƒìƒ‰

**ì…ë ¥**: 
- `train` - í›ˆë ¨ìš© ë°ì´í„°

**ì¶œë ¥**:
- `best_model` - ìµœì  ì„¤ì •ìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸

**ì„¤ì •**:
- `method`: íƒìƒ‰ ë°©ë²• (GridSearch, RandomSearch)

**ìƒì„±ë˜ëŠ” ì½”ë“œ**:
```python
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [10, 20, 30]
}
step_node_6 = GridSearchCV(
    RandomForestClassifier(random_state=42), 
    param_grid, 
    cv=5
)
step_node_6.fit(X_train_scaled, y_train)
print(f"Best parameters: {step_node_6.best_params_}")
print(f"Best score: {step_node_6.best_score_:.4f}")
```

**íƒìƒ‰ ê³¼ì •**:
```
ì‹œë„ 1: n_estimators=50,  max_depth=10  â†’ Accuracy: 0.92
ì‹œë„ 2: n_estimators=50,  max_depth=20  â†’ Accuracy: 0.94
ì‹œë„ 3: n_estimators=100, max_depth=10  â†’ Accuracy: 0.95
ì‹œë„ 4: n_estimators=100, max_depth=20  â†’ Accuracy: 0.96 âœ“ ìµœê³ !
...
ìµœì¢…: n_estimators=100, max_depth=20 ì„ íƒ
```

**íš¨ê³¼**:
- ìˆ˜ë™ ì¡°ì • ì‹œê°„ ì ˆì•½
- ë” ë‚˜ì€ ì„±ëŠ¥ ë°œê²¬
- ì²´ê³„ì ì¸ ì‹¤í—˜ ê´€ë¦¬

---

## ğŸ”— ë…¸ë“œ ì—°ê²° ì˜ˆì‹œ

### ê¸°ë³¸ ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸:
```
Data Loader â†’ Data Split â†’ Scaler â†’ Classifier â†’ Evaluate
    â†“             â†“          â†“           â†“           â†“
  iris.csv    80/20 ë¶„í•    ì •ê·œí™”    RandomForest  96.7%
```

### ê³ ê¸‰ ìµœì í™” íŒŒì´í”„ë¼ì¸:
```
Data Loader â†’ Data Split â†’ Scaler â†’ Feature Selection â†’ Hyperparameter Tuning â†’ Evaluate
```

### ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸:
```
Data Loader â†’ Scaler â†’ Trained Model â†’ Predict
                                           â†“
                                    [0,1,2,1,0...]
```

---

## ğŸ’¡ ê° ë…¸ë“œê°€ í•˜ëŠ” ì¼ ìš”ì•½í‘œ

| ë…¸ë“œ | ì…ë ¥ | ì¶œë ¥ | í•µì‹¬ ì—­í•  |
|------|------|------|-----------|
| Data Loader | - | DataFrame | ë°ì´í„° ë¡œë“œ |
| Data Split | ë°ì´í„° | Train/Test | í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬ |
| Scaler | ë°ì´í„° | ì •ê·œí™” ë°ì´í„° | íŠ¹ì„± ìŠ¤ì¼€ì¼ë§ |
| Feature Selection | ë°ì´í„° | ì„ íƒëœ íŠ¹ì„± | ì¤‘ìš” ë³€ìˆ˜ ì¶”ì¶œ |
| Classifier | í›ˆë ¨ ë°ì´í„° | ë¶„ë¥˜ ëª¨ë¸ | ì¹´í…Œê³ ë¦¬ ì˜ˆì¸¡ í•™ìŠµ |
| Regressor | í›ˆë ¨ ë°ì´í„° | íšŒê·€ ëª¨ë¸ | ìˆ«ì ì˜ˆì¸¡ í•™ìŠµ |
| Neural Network | í›ˆë ¨ ë°ì´í„° | ì‹ ê²½ë§ ëª¨ë¸ | ë³µì¡í•œ íŒ¨í„´ í•™ìŠµ |
| Evaluate | ëª¨ë¸ + í…ŒìŠ¤íŠ¸ | í‰ê°€ ì§€í‘œ | ì„±ëŠ¥ ì¸¡ì • |
| Predict | ëª¨ë¸ + ë°ì´í„° | ì˜ˆì¸¡ê°’ | ì‹¤ì œ ì˜ˆì¸¡ ìˆ˜í–‰ |
| Hyperparameter Tuning | í›ˆë ¨ ë°ì´í„° | ìµœì  ëª¨ë¸ | íŒŒë¼ë¯¸í„° ìë™ íƒìƒ‰ |

---

## ğŸ“š í•™ìŠµ ìë£Œ

### ì´ˆë³´ììš© íŒŒì´í”„ë¼ì¸
```
Data Loader â†’ Data Split â†’ Classifier â†’ Evaluate
```
- ê°€ì¥ ë‹¨ìˆœí•œ êµ¬ì¡°
- Iris ë°ì´í„°ì…‹ìœ¼ë¡œ ì‹¤ìŠµ ì¶”ì²œ

### ì¤‘ê¸‰ììš© íŒŒì´í”„ë¼ì¸
```
Data Loader â†’ Data Split â†’ Scaler â†’ Feature Selection â†’ Classifier â†’ Evaluate
```
- ì „ì²˜ë¦¬ ë‹¨ê³„ ì¶”ê°€
- ì‹¤ë¬´ì—ì„œ ê°€ì¥ ë§ì´ ì‚¬ìš©

### ê³ ê¸‰ììš© íŒŒì´í”„ë¼ì¸
```
Data Loader â†’ Data Split â†’ Scaler â†’ Hyperparameter Tuning â†’ Evaluate â†’ Predict
```
- ìµœì í™” ë‹¨ê³„ í¬í•¨
- í”„ë¡œë•ì…˜ ë ˆë²¨ íŒŒì´í”„ë¼ì¸

---

## ğŸ“ ë‹¤ìŒ ë‹¨ê³„

1. **ì‹¤ìŠµ**: `examples/iris_classification_example.ipynb` ë…¸íŠ¸ë¶ ì‹¤í–‰
2. **ì»¤ìŠ¤í„°ë§ˆì´ì§•**: ê° ë…¸ë“œì˜ íŒŒë¼ë¯¸í„° ë³€ê²½í•´ë³´ê¸°
3. **ìƒˆ ë°ì´í„°ì…‹**: ìì‹ ì˜ CSV íŒŒì¼ë¡œ íŒŒì´í”„ë¼ì¸ êµ¬ì„±
4. **ì½”ë“œ í•™ìŠµ**: ìƒì„±ëœ Python ì½”ë“œ ë¶„ì„
5. **ë°°í¬**: í•™ìŠµëœ ëª¨ë¸ì„ ì‹¤ì œ ì„œë¹„ìŠ¤ì— ì ìš©

---

**í”„ë¡œì íŠ¸ ì €ì¥ì†Œ**: https://github.com/enderpawar/2025_oss_term_project-22101203_-

**ë¬¸ì˜ ë° ê¸°ì—¬**: Issuesì™€ Pull Requests í™˜ì˜í•©ë‹ˆë‹¤! ğŸ™Œ
